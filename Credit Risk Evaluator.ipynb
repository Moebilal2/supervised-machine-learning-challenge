{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77531</th>\n",
       "      <td>19100.0</td>\n",
       "      <td>11.261</td>\n",
       "      <td>86600</td>\n",
       "      <td>0.653580</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>56600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77532</th>\n",
       "      <td>17700.0</td>\n",
       "      <td>10.662</td>\n",
       "      <td>80900</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77533</th>\n",
       "      <td>17600.0</td>\n",
       "      <td>10.595</td>\n",
       "      <td>80300</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77534</th>\n",
       "      <td>16300.0</td>\n",
       "      <td>10.068</td>\n",
       "      <td>75300</td>\n",
       "      <td>0.601594</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77535</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>9.742</td>\n",
       "      <td>72300</td>\n",
       "      <td>0.585062</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>42300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77536 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "0        10700.0          7.672            52800        0.431818   \n",
       "1         8400.0          6.692            43600        0.311927   \n",
       "2         9000.0          6.963            46100        0.349241   \n",
       "3        10700.0          7.664            52700        0.430740   \n",
       "4        10800.0          7.698            53000        0.433962   \n",
       "...          ...            ...              ...             ...   \n",
       "77531    19100.0         11.261            86600        0.653580   \n",
       "77532    17700.0         10.662            80900        0.629172   \n",
       "77533    17600.0         10.595            80300        0.626401   \n",
       "77534    16300.0         10.068            75300        0.601594   \n",
       "77535    15600.0          9.742            72300        0.585062   \n",
       "\n",
       "       num_of_accounts  derogatory_marks  total_debt  loan_status  \n",
       "0                    5                 1       22800            0  \n",
       "1                    3                 0       13600            0  \n",
       "2                    3                 0       16100            0  \n",
       "3                    5                 1       22700            0  \n",
       "4                    5                 1       23000            0  \n",
       "...                ...               ...         ...          ...  \n",
       "77531               12                 2       56600            1  \n",
       "77532               11                 2       50900            1  \n",
       "77533               11                 2       50300            1  \n",
       "77534               10                 2       45300            1  \n",
       "77535                9                 2       42300            1  \n",
       "\n",
       "[77536 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "df=pd.read_csv(\"Resources/lending_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions before testing models: In comparison between Logistic Regression and Random forrest classifier, I think Random Forest classifier will show better score and accuracy due to that it uses manu decision trees and get the best results from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "x=df.drop(columns=[\"loan_status\"]).values\n",
    "y=df[\"loan_status\"].values\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908171687990095"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression model print the model score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using normalization:\n",
    "scaler=MinMaxScaler().fit(x_train)\n",
    "x_train_scaled=scaler.transform(x_train)\n",
    "x_test_scaled=scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify parameters for hyperparameter test using GridSearchCV\n",
    "param_grid = {\n",
    "    'penalty': [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "    'C': [100, 10, 1.0, 0.1, 0.01]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=l2;, score=0.995 total time=   0.8s\n",
      "[CV 2/5] END .................C=100, penalty=l2;, score=0.994 total time=   0.3s\n",
      "[CV 3/5] END .................C=100, penalty=l2;, score=0.994 total time=   0.5s\n",
      "[CV 4/5] END .................C=100, penalty=l2;, score=0.994 total time=   0.4s\n",
      "[CV 5/5] END .................C=100, penalty=l2;, score=0.994 total time=   0.4s\n",
      "[CV 1/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...........C=100, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............C=100, penalty=none;, score=0.995 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............C=100, penalty=none;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............C=100, penalty=none;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...............C=100, penalty=none;, score=0.994 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...............C=100, penalty=none;, score=0.994 total time=   0.5s\n",
      "[CV 1/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=l2;, score=0.994 total time=   0.3s\n",
      "[CV 2/5] END ..................C=10, penalty=l2;, score=0.994 total time=   0.1s\n",
      "[CV 3/5] END ..................C=10, penalty=l2;, score=0.993 total time=   0.2s\n",
      "[CV 4/5] END ..................C=10, penalty=l2;, score=0.993 total time=   0.2s\n",
      "[CV 5/5] END ..................C=10, penalty=l2;, score=0.994 total time=   0.2s\n",
      "[CV 1/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ............C=10, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................C=10, penalty=none;, score=0.995 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................C=10, penalty=none;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ................C=10, penalty=none;, score=0.994 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ................C=10, penalty=none;, score=0.994 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ................C=10, penalty=none;, score=0.994 total time=   0.5s\n",
      "[CV 1/5] END ...................C=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.994 total time=   0.2s\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.993 total time=   0.2s\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.992 total time=   0.1s\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.992 total time=   0.1s\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.993 total time=   0.2s\n",
      "[CV 1/5] END ...........C=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...........C=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........C=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...........C=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...........C=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............C=1.0, penalty=none;, score=0.995 total time=   0.4s\n",
      "[CV 2/5] END ...............C=1.0, penalty=none;, score=0.994 total time=   0.4s\n",
      "[CV 3/5] END ...............C=1.0, penalty=none;, score=0.994 total time=   0.4s\n",
      "[CV 4/5] END ...............C=1.0, penalty=none;, score=0.994 total time=   0.5s\n",
      "[CV 5/5] END ...............C=1.0, penalty=none;, score=0.994 total time=   0.5s\n",
      "[CV 1/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.993 total time=   0.1s\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.993 total time=   0.1s\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.992 total time=   0.1s\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.992 total time=   0.1s\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.993 total time=   0.1s\n",
      "[CV 1/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.1, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............C=0.1, penalty=none;, score=0.995 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............C=0.1, penalty=none;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............C=0.1, penalty=none;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...............C=0.1, penalty=none;, score=0.994 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...............C=0.1, penalty=none;, score=0.994 total time=   0.5s\n",
      "[CV 1/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.01, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.988 total time=   0.1s\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.987 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.986 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.988 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.988 total time=   0.1s\n",
      "[CV 1/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.01, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..............C=0.01, penalty=none;, score=0.995 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..............C=0.01, penalty=none;, score=0.994 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..............C=0.01, penalty=none;, score=0.994 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..............C=0.01, penalty=none;, score=0.994 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..............C=0.01, penalty=none;, score=0.994 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.99418763        nan 0.99420483        nan 0.99360295\n",
      "        nan 0.99420483        nan 0.99281192        nan 0.99420483\n",
      "        nan 0.99253678        nan 0.99420483        nan 0.98751548\n",
      "        nan 0.99420483]\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohamed\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creat gridsearch and fit the data\n",
    "grid_clf = GridSearchCV(model, param_grid, verbose=3)\n",
    "grid_clf.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'penalty': 'none'}\n",
      "0.9942048294603335\n"
     ]
    }
   ],
   "source": [
    "#show the best parameters and best score\n",
    "print(grid_clf.best_params_)\n",
    "print(grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions with the hypertuned model and get the score on test data\n",
    "predictions = grid_clf.predict(x_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18723\n",
      "           1       0.86      0.98      0.92       661\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.99      0.96     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910751134956666"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create random forrest model\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify parameters for hyperparameter test using GridSearchCV\n",
    "param_grid2 = {\n",
    "    'n_estimators': [200, 400, 600, 800, 1000],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END max_features=auto, n_estimators=200;, score=0.993 total time=  12.2s\n",
      "[CV 2/5] END max_features=auto, n_estimators=200;, score=0.993 total time=  13.3s\n",
      "[CV 3/5] END max_features=auto, n_estimators=200;, score=0.992 total time=  15.3s\n",
      "[CV 4/5] END max_features=auto, n_estimators=200;, score=0.992 total time=  16.1s\n",
      "[CV 5/5] END max_features=auto, n_estimators=200;, score=0.992 total time=  15.2s\n",
      "[CV 1/5] END max_features=auto, n_estimators=400;, score=0.993 total time=  30.8s\n",
      "[CV 2/5] END max_features=auto, n_estimators=400;, score=0.993 total time=  30.4s\n",
      "[CV 3/5] END max_features=auto, n_estimators=400;, score=0.991 total time=  27.9s\n",
      "[CV 4/5] END max_features=auto, n_estimators=400;, score=0.992 total time=  31.6s\n",
      "[CV 5/5] END max_features=auto, n_estimators=400;, score=0.992 total time=  35.1s\n",
      "[CV 1/5] END max_features=auto, n_estimators=600;, score=0.993 total time=  40.9s\n",
      "[CV 2/5] END max_features=auto, n_estimators=600;, score=0.993 total time=  55.9s\n",
      "[CV 3/5] END max_features=auto, n_estimators=600;, score=0.991 total time=  48.6s\n",
      "[CV 4/5] END max_features=auto, n_estimators=600;, score=0.991 total time=  56.4s\n",
      "[CV 5/5] END max_features=auto, n_estimators=600;, score=0.992 total time=  54.7s\n",
      "[CV 1/5] END max_features=auto, n_estimators=800;, score=0.993 total time= 1.1min\n",
      "[CV 2/5] END max_features=auto, n_estimators=800;, score=0.993 total time= 1.3min\n",
      "[CV 3/5] END max_features=auto, n_estimators=800;, score=0.991 total time=  58.4s\n",
      "[CV 4/5] END max_features=auto, n_estimators=800;, score=0.991 total time= 1.1min\n",
      "[CV 5/5] END max_features=auto, n_estimators=800;, score=0.992 total time=  59.1s\n",
      "[CV 1/5] END max_features=auto, n_estimators=1000;, score=0.993 total time= 1.0min\n",
      "[CV 2/5] END max_features=auto, n_estimators=1000;, score=0.993 total time= 1.0min\n",
      "[CV 3/5] END max_features=auto, n_estimators=1000;, score=0.991 total time= 1.1min\n",
      "[CV 4/5] END max_features=auto, n_estimators=1000;, score=0.991 total time= 1.2min\n",
      "[CV 5/5] END max_features=auto, n_estimators=1000;, score=0.992 total time= 1.4min\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=200;, score=0.993 total time=  17.6s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=200;, score=0.993 total time=  14.1s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=200;, score=0.992 total time=  12.5s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=200;, score=0.992 total time=  12.7s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=200;, score=0.992 total time=  13.5s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=400;, score=0.993 total time=  31.2s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=400;, score=0.993 total time=  35.6s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=400;, score=0.991 total time=  31.1s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=400;, score=0.992 total time=  30.6s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=400;, score=0.992 total time=  31.7s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=600;, score=0.993 total time=  51.8s\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=600;, score=0.993 total time=  57.3s\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=600;, score=0.991 total time=  57.0s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=600;, score=0.991 total time=  55.9s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=600;, score=0.992 total time=  55.1s\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=800;, score=0.993 total time= 1.2min\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=800;, score=0.993 total time= 1.1min\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=800;, score=0.991 total time=  50.7s\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=800;, score=0.991 total time=  56.1s\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=800;, score=0.992 total time= 1.5min\n",
      "[CV 1/5] END max_features=sqrt, n_estimators=1000;, score=0.993 total time= 1.5min\n",
      "[CV 2/5] END max_features=sqrt, n_estimators=1000;, score=0.993 total time= 1.5min\n",
      "[CV 3/5] END max_features=sqrt, n_estimators=1000;, score=0.991 total time= 1.3min\n",
      "[CV 4/5] END max_features=sqrt, n_estimators=1000;, score=0.991 total time= 1.6min\n",
      "[CV 5/5] END max_features=sqrt, n_estimators=1000;, score=0.992 total time= 1.4min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=1),\n",
       "             param_grid={'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [200, 400, 600, 800, 1000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creat gridsearch and fit the data\n",
    "grid_clf2 = GridSearchCV(clf, param_grid2, verbose=3)\n",
    "grid_clf2.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 400}\n",
      "0.9922100476733207\n"
     ]
    }
   ],
   "source": [
    "#show the best parameters and best score\n",
    "print(grid_clf2.best_params_)\n",
    "print(grid_clf2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions with the hypertuned model and get the score on test data\n",
    "predictions2 = grid_clf2.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18723\n",
      "           1       0.86      0.89      0.87       661\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.94      0.93     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "print(classification_report(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
